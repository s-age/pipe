# Default model to use
model: gemini-2.5-flash
context_limit: 1000000

# The language hint for the model
language: "English"

# Auto-confirm for gemini-cli. If false, the -y flag will be omitted.
yolo: false

# gemini-cli | gemini-api(experimental)
api_mode: "gemini-cli"

# Hyperparameters to be included in the prompt as contextual hints
parameters:
  temperature:
    value: 0.2
    description: "Be precise and factual. A lower value is preferred for deterministic output."
  top_p:
    value: 0.5
    description: "Consider a broad range of possibilities, but adhere strictly to the temperature setting."
  top_k:
    value: 5
    description: "Limit the generation to the top 5 most likely tokens at each step."
  max_output_tokens:
    value: 100
    description: "The maximum number of tokens to generate in the response."
